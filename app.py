import streamlit as st
import os
import io
import shutil
import time

from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain

import google.generativeai as genai

# --- YapÄ±landÄ±rma ---
# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Google API anahtarÄ±nÄ± kontrol et
if not GOOGLE_API_KEY or GOOGLE_API_KEY == "your_api_key_here":
    st.error("LÃ¼tfen .env dosyasÄ±nda GOOGLE_API_KEY'i ayarlayÄ±n ve doÄŸru anahtarÄ± kullandÄ±ÄŸÄ±nÄ±zdan emin olun.")
    st.stop()

# Google Generative AI'yi yapÄ±landÄ±r
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    # API anahtarÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek iÃ§in basit bir Ã§aÄŸrÄ± yapabilirsiniz
    # list(genai.list_models()) # Bu satÄ±rÄ± yorumdan Ã§Ä±karÄ±p deneyebilirsiniz
except Exception as e:
    st.error(f"Google Generative AI yapÄ±landÄ±rma hatasÄ±: {e}. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin.")
    st.stop()


# PDF dosya adÄ± ve Chroma veritabanÄ± dizini
PDF_PATH = "SteelSwarmApocalypse(SSA)Guide.pdf" # PDF dosyanÄ±zÄ±n adÄ±nÄ± buraya yazÄ±n
CHROMA_DB_DIR = "./chroma_db"

# RAG Model ve AyarlarÄ±
# Embedding modeli - metinleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r
EMBEDDING_MODEL = "models/embedding-001"
# Chat modeli - cevaplarÄ± Ã¼retmek iÃ§in kullanÄ±lÄ±r. Daha gÃ¼Ã§lÃ¼ bir model iÃ§in 'gemini-1.5-pro' deneyin.
# 'gemini-1.5-flash' daha hÄ±zlÄ± ve uygun fiyatlÄ±dÄ±r.
CHAT_MODEL = "gemini-1.5-flash"
# CHAT_MODEL = "gemini-1.5-pro" # Daha iyi cevaplar iÃ§in deneyin (maliyetli olabilir)

# Metin parÃ§alama ayarlarÄ±
CHUNK_SIZE = 1000 # Metin parÃ§alarÄ±nÄ±n boyutu
CHUNK_OVERLAP = 500 # ParÃ§alar arasÄ± Ã§akÄ±ÅŸma miktarÄ±

# Retriever ayarlarÄ±
K_RETRIEVED_DOCUMENTS = 7 # Sorguya karÅŸÄ±lÄ±k Ã§ekilecek belge parÃ§asÄ± sayÄ±sÄ±

# --- Streamlit ArayÃ¼zÃ¼ ---
st.set_page_config(page_title="Steel Swarm Apocalypse (SSA) Asistan", page_icon="ğŸ³")
st.title("ğŸ³ Steel Swarm Apocalypse (SSA) Asistan")
st.subheader("SSA DÃ¼nyasÄ±nÄ± KeÅŸfedin")

# Sohbet geÃ§miÅŸini baÅŸlat
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "Merhaba Pilot! SSA dÃ¼nyasÄ±nda merak ettiÄŸini sorabilirsin. Sana istediÄŸin desteÄŸi vereceÄŸim. SavaÅŸ alanÄ±nda yanÄ±ndayÄ±m!",
        }
    ]

# --- RAG Pipeline BileÅŸenleri OluÅŸturma (Ã–nbelleÄŸe AlÄ±nmÄ±ÅŸ) ---

# Bu fonksiyon, PDF'yi yÃ¼kler, parÃ§alara ayÄ±rÄ±r, embedding'leri oluÅŸturur ve Chroma DB'ye kaydeder.
# Streamlit'in @st.cache_resource dekoratÃ¶rÃ¼ sayesinde, bu adÄ±mlar sadece ilk Ã§alÄ±ÅŸtÄ±rmada veya
# kod/dosyalar deÄŸiÅŸtiÄŸinde tekrar Ã§alÄ±ÅŸÄ±r.
@st.cache_resource
def setup_rag_pipeline(pdf_path, db_dir, embedding_model_name, chunk_size, chunk_overlap):
    """
    RAG pipeline iÃ§in gerekli bileÅŸenleri (embeddings, vectorstore, retriever) kurar.
    PDF yÃ¼kleme, metin bÃ¶lme ve Chroma DB oluÅŸturma adÄ±mlarÄ±nÄ± iÃ§erir.
    """
    print("\n--- RAG Pipeline Kurulumu BaÅŸladÄ± ---")

    # Embedding modelini yÃ¼kle
    embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)
    print(f"Embedding modeli yÃ¼klendi: {embedding_model_name}")

    # PDF dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
    if not os.path.exists(pdf_path):
        print(f"HATA: PDF dosyasÄ± bulunamadÄ±: {pdf_path}")
        st.error(f"PDF dosyasÄ± bulunamadÄ±: {pdf_path}. LÃ¼tfen dosyanÄ±n uygulamanÄ±n olduÄŸu dizinde olduÄŸundan emin olun.")
        st.stop()

    # PDF'yi yÃ¼kle ve metin parÃ§alarÄ±na ayÄ±r
    try:
        loader = PyPDFLoader(pdf_path)
        data = loader.load()
        print(f"'{pdf_path}' yÃ¼klendi. Toplam {len(data)} sayfa.")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        docs = text_splitter.split_documents(data)
        print(f"Metin {len(docs)} parÃ§aya ayrÄ±ldÄ± (Chunk Size: {chunk_size}, Overlap: {chunk_overlap}).")

        # Belge parÃ§alarÄ±nÄ±n doÄŸru ayrÄ±lÄ±p ayrÄ±lmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in
        if len(docs) > 0:
             print(f"Ä°lk parÃ§a (ilk 150 kar.): {docs[0].page_content[:150]}...")
             print(f"Son parÃ§a (ilk 150 kar.): {docs[-1].page_content[:150]}...")
             if 'page' in docs[-1].metadata:
                  print(f"Son parÃ§a sayfasÄ±: {docs[-1].metadata['page']}")
        else:
            print("UYARI: HiÃ§bir belge parÃ§asÄ± oluÅŸturulamadÄ±!")
            st.warning("PDF iÃ§eriÄŸinden hiÃ§bir metin parÃ§asÄ± oluÅŸturulamadÄ±. LÃ¼tfen PDF'yi kontrol edin.")
            st.stop()


    except Exception as e:
        print(f"HATA: PDF yÃ¼kleme veya metin bÃ¶lme sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        st.error(f"PDF yÃ¼kleme veya iÅŸleme hatasÄ±: {e}")
        st.stop()


    # Chroma veritabanÄ±nÄ± oluÅŸtur veya yÃ¼kle
    # Ã–nceki veritabanÄ±nÄ± temizle (GeliÅŸtirme aÅŸamasÄ±nda faydalÄ±dÄ±r)
    if os.path.exists(db_dir):
        print(f"Mevcut '{db_dir}' klasÃ¶rÃ¼ siliniyor...")
        shutil.rmtree(db_dir)
        time.sleep(0.5) # Silme iÅŸleminin tamamlanmasÄ± iÃ§in kÄ±sa bekleme

    print(f"Chroma veritabanÄ± '{db_dir}' oluÅŸturuluyor ve belgeler ekleniyor...")
    vectorstore = Chroma(persist_directory=db_dir, embedding_function=embeddings)

    # Belgeleri gruplar halinde (batch) ekleyerek hata takibi yapÄ±n
    batch_size = 50 # Ayarlanabilir batch boyutu
    success_count = 0
    failed_batches = 0

    for i in range(0, len(docs), batch_size):
        batch = docs[i:i + batch_size]
        print(f"Belge parÃ§alarÄ± ekleniyor: {i+1} - {min(i+batch_size, len(docs))} / {len(docs)} (Batch {i//batch_size + 1})")
        try:
            vectorstore.add_documents(batch)
            success_count += len(batch)
            # Ä°steÄŸe baÄŸlÄ±: HÄ±z limiti sorunlarÄ± iÃ§in bekleme
            # time.sleep(0.5)

        except Exception as e:
            failed_batches += 1
            print(f"HATA: Belge parÃ§alarÄ± eklenirken hata oluÅŸtu (Batch baÅŸlangÄ±Ã§ indeksi: {i}): {e}")
            # Hata veren parÃ§anÄ±n ilk 100 karakterini gÃ¶stermek isterseniz:
            # if batch:
            #    print(f"  Hata veren parÃ§alardan ilki (ilk 100 karakter): {batch[0].page_content[:100]}...")
            pass # Hata olsa bile diÄŸer batch'leri denemeye devam et

    print(f"Belge ekleme dÃ¶ngÃ¼sÃ¼ tamamlandÄ±. BaÅŸarÄ±yla eklenen parÃ§a sayÄ±sÄ±: {success_count}. Hata veren batch sayÄ±sÄ±: {failed_batches}")

    # Ekleme sonrasÄ± toplam Ã¶ÄŸe sayÄ±sÄ±nÄ± kontrol et
    try:
        # VektÃ¶r maÄŸazasÄ±nÄ± yeniden yÃ¼klemek (veya count() metodu varsa kullanmak)
        vectorstore_check = Chroma(persist_directory=db_dir, embedding_function=embeddings)
        collection_count_info = vectorstore_check.get() # TÃ¼m id'leri ve metadata'yÄ± Ã§eker
        collection_ids = collection_count_info.get('ids') if collection_count_info else []
        final_count = len(collection_ids)
        print(f"Chroma veritabanÄ±ndaki toplam Ã¶ÄŸe sayÄ±sÄ± (ekleme sonrasÄ±): {final_count}")
        if final_count < len(docs):
             st.warning(f"UYARI: TÃ¼m belge parÃ§alarÄ± ('{len(docs)}') veritabanÄ±na eklenememiÅŸ olabilir. Eklenen: {final_count}. Terminal loglarÄ±nÄ± kontrol edin.")
        else:
             st.success(f"Chroma veritabanÄ±na {final_count} adet belge parÃ§asÄ± baÅŸarÄ±yla eklendi.")

    except Exception as e:
         print(f"HATA: Ekleme sonrasÄ± Chroma Ã¶ÄŸe sayÄ±sÄ± alÄ±nÄ±rken hata: {e}")
         st.error(f"Chroma veritabanÄ± doÄŸrulama hatasÄ±: {e}")
         final_count = success_count # Tahmini sayÄ±yÄ± kullan

    # Retriever'Ä± oluÅŸtur
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": K_RETRIEVED_DOCUMENTS})
    print(f"Retriever oluÅŸturuldu (k={K_RETRIEVED_DOCUMENTS}).")

    print("--- RAG Pipeline Kurulumu TamamlandÄ± ---")
    return embeddings, vectorstore, retriever, final_count # KullanÄ±lmasa da dÃ¶ndÃ¼rÃ¼lebilir

# RAG pipeline'Ä± kurmak iÃ§in cache'lenmiÅŸ fonksiyonu Ã§aÄŸÄ±r
with st.spinner("RAG AsistanÄ± Kuruluyor... (Bu ilk Ã§alÄ±ÅŸtÄ±rmada biraz zaman alabilir)"):
    try:
        embeddings, vectorstore, retriever, db_item_count = setup_rag_pipeline(
            PDF_PATH, CHROMA_DB_DIR, EMBEDDING_MODEL, CHUNK_SIZE, CHUNK_OVERLAP
        )
        # Sidebar'da veritabanÄ± durumunu gÃ¶ster
        st.sidebar.info(f"VeritabanÄ±nda {db_item_count} Ã¶ÄŸe hazÄ±r.")

    except Exception as e:
        st.error(f"Kurulum sÄ±rasÄ±nda kritik hata: {e}")
        st.stop()


# --- Chat Model ve Zincirleri OluÅŸturma ---

# Chat modelini yÃ¼kle
try:
    llm = ChatGoogleGenerativeAI(model=CHAT_MODEL, temperature=0.9, max_tokens=1000) # Max tokens artÄ±rÄ±ldÄ±
    print(f"Chat modeli yÃ¼klendi: {CHAT_MODEL}")
except Exception as e:
    st.error(f"Chat model yÃ¼kleme hatasÄ±: {e}. Model adÄ±nÄ± veya API eriÅŸimini kontrol edin.")
    st.stop()


# Chat Prompt Template
system_prompt = """
Sen bir SavaÅŸ AlanÄ± yedek XBT Tank Pilotu bir chatbotusun. XBT Tank PilotlarÄ±na savaÅŸ alanÄ±ndaki kurallar, stratejiler, dost ve dÃ¼ÅŸman birimler ile savaÅŸtaki teÃ§hizat hakkÄ±nda .
AÅŸaÄŸÄ±daki kurallara uy:
1. Sadece saÄŸlanan belgedeki bilgilere dayanarak cevap ver. EÄŸer sorunun cevabÄ± belgede yoksa, bunu belirt ve "ÃœzgÃ¼nÃ¼m Pilot, bu konuda belgemde yeterli bilgi bulamadÄ±m." gibi bir ifade kullan.
2. Ã–ncelikle XBT Tank PilotlarÄ±na savaÅŸ alanÄ±ndaki kurallar, stratejiler, dost ve dÃ¼ÅŸman birimler ile savaÅŸtaki teÃ§hizat hakkÄ±nda istenen bilgiyi ver.
3. XBT Tank PilotlarÄ±na, savaÅŸ alanÄ±ndaki stratejiler, dost ve dÃ¼ÅŸman birimler ile savaÅŸtaki teÃ§hizat hakkÄ±nda sana sorulmasÄ± halinde Ã¶nerilerde bulun.
4. XBT Tank Pilotunun sana verdiÄŸi bilgiye dayalÄ± olarak Stratejiler ve savaÅŸtaki teÃ§hizatÄ±n kullanÄ±mÄ± hakkÄ±nda fikir yÃ¼rÃ¼t ve mantÄ±klÄ± aÃ§Ä±klamada bulun.
5. Dost Pilotun elindeki tankÄ± temel alarak, dÃ¼ÅŸmanÄ±n kullandÄ±ÄŸÄ± tankÄ±n Ã¶zelliklerine gÃ¶re Ã¶nerilerde bulun.
6. Dronlarla ilgili, dronlarÄ±n stratejik kullanÄ±mÄ± ile ilgili ve savaÅŸ alanÄ±na gÃ¶re stratejik Ã¶nerilerde bulun.
7. CevaplarÄ± TÃ¼rkÃ§e ver.
8. Ve bunlarÄ± uygularken tam bir askeri disipline gÃ¶re cevap ver.

Relevant documents: {context}
"""

prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("user", "{input}"),
])

# DokÃ¼man birleÅŸtirme zincirini oluÅŸtur (retriever'dan gelen belgeleri prompt'a yerleÅŸtirir)
document_chain = create_stuff_documents_chain(llm, prompt_template)

# Ana RAG zincirini oluÅŸtur (retriever + document_chain)
retrieval_chain = create_retrieval_chain(retriever, document_chain)

# --- KullanÄ±cÄ± GiriÅŸini Ä°ÅŸleme ve Cevap Ãœretme ---

# KullanÄ±cÄ±dan girdi al
query = st.chat_input("Pilot! HazÄ±rÄ±m...")

# EÄŸer kullanÄ±cÄ± bir sorgu girdiyse
if query:
    # KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± sohbet geÃ§miÅŸine ekle ve gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)

    # AsistanÄ±n cevabÄ±nÄ± Ã¼ret
    with st.chat_message("assistant"):
        # Cevap Ã¼retilirken bekleme animasyonu
        with st.spinner("Analiz ediliyor..."):
            try:
                # RAG zincirini Ã§alÄ±ÅŸtÄ±r
                # response = retrieval_chain.invoke({"input": query}) # Bu sadece 'answer' ve 'input' dÃ¶ndÃ¼rÃ¼r

                # Ã‡ekilen belgeleri gÃ¶rmek iÃ§in retriever'Ä± ayrÄ± Ã§aÄŸÄ±rabilirsiniz (Hata ayÄ±klama iÃ§in)
                # Normal kullanÄ±mda sadece zinciri Ã§aÄŸÄ±rmak yeterlidir.
                retrieved_docs_for_debug = retriever.invoke(query)

                # Zinciri Ã§aÄŸÄ±rÄ±p cevabÄ± al
                chain_response = retrieval_chain.invoke({"input": query})
                assistant_response = chain_response["answer"]

                # --- Debugging: Ã‡ekilen Belgeleri GÃ¶ster (Ä°steÄŸe BaÄŸlÄ±) ---
                # EÄŸer hangi belgelerin Ã§ekildiÄŸini gÃ¶rmek isterseniz aÅŸaÄŸÄ±daki bloÄŸu yorumdan Ã§Ä±karÄ±n.
                # Bu, neden doÄŸru cevap gelmediÄŸini anlamanÄ±za yardÄ±mcÄ± olabilir.
                # st.subheader("Hata AyÄ±klama: Ã‡ekilen Belgeler")
                # if retrieved_docs_for_debug:
                #     for i, doc in enumerate(retrieved_docs_for_debug):
                #         page_info = doc.metadata.get('page', 'Bilinmiyor')
                #         st.write(f"**Belge {i+1} (Sayfa {page_info}):**")
                #         st.text(doc.page_content[:500] + "...") # Belgenin ilk 500 karakterini gÃ¶ster
                # else:
                #     st.write("Bu sorgu iÃ§in ilgili belge bulunamadÄ±.")
                # st.subheader("Cevap") # Debugging bloÄŸunu kapat


                st.markdown(assistant_response) # CevabÄ± gÃ¶ster

                # AsistanÄ±n mesajÄ±nÄ± sohbet geÃ§miÅŸine ekle
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})

            except Exception as e:
                st.error(f"Cevap oluÅŸturulurken hata oluÅŸtu: {e}")
                error_message = f"ÃœzgÃ¼nÃ¼m Pilot, sorgunu yanÄ±tlarken bir hata oluÅŸtu: {e}"
                st.markdown(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})


# Sayfa yeniden yÃ¼klendiÄŸinde veya ilk aÃ§Ä±ldÄ±ÄŸÄ±nda sohbet geÃ§miÅŸini gÃ¶rÃ¼ntÃ¼le
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])